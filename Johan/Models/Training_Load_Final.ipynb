{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc1ZxeMHt9qM",
        "outputId": "e0de8577-4452-43d6-89f8-c730bfc500b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Features: ['Micro-cycle', 'Position', 'MatchDay', 'Sleep', 'Stress', 'Fatigue', 'Pain', 'Wellness', 'RPE', 'Duration', 'Acute', 'Chronic', 'ACWR', 'Total Duration', 'TD/min', 'Dist MP 20-35W', 'Dist MP 35-55W', 'Dist MP>55 W', 'Distance 14,4-19,8 km/h / min', 'Distance 19,8-25 km/h / min', 'Distance > 25 km/h / min', 'Dist Acc>3 / min', 'Dist Dec <-3 / min', 'Dist Acc 2-3 / min', 'Dist Dec 2-3 / min', 'Dist MP 20-35W / min', 'Dist MP 35-55W / min', 'Dist MP>55 W / min']\n",
            "Feature Order after Encoding: ['Micro-cycle', 'Position', 'MatchDay', 'Sleep', 'Stress', 'Fatigue', 'Pain', 'Wellness', 'RPE', 'Duration', 'Acute', 'Chronic', 'ACWR', 'Total Duration', 'TD/min', 'Dist MP 20-35W', 'Dist MP 35-55W', 'Dist MP>55 W', 'Distance 14,4-19,8 km/h / min', 'Distance 19,8-25 km/h / min', 'Distance > 25 km/h / min', 'Dist Acc>3 / min', 'Dist Dec <-3 / min', 'Dist Acc 2-3 / min', 'Dist Dec 2-3 / min', 'Dist MP 20-35W / min', 'Dist MP 35-55W / min', 'Dist MP>55 W / min']\n",
            "PCA Component Contributions:\n",
            "      Micro-cycle  Position  MatchDay     Sleep    Stress   Fatigue      Pain  \\\n",
            "PC1      0.002268  0.006033 -0.217355 -0.080298 -0.093121 -0.109557 -0.116808   \n",
            "PC2     -0.013239  0.007156  0.007565  0.059811  0.044373  0.044817  0.048826   \n",
            "PC3      0.023151  0.101491 -0.025318  0.345301  0.276315  0.303130  0.326805   \n",
            "PC4     -0.016113  0.001658 -0.043756  0.208194  0.187000  0.318597  0.279312   \n",
            "PC5     -0.010396 -0.451270 -0.052077 -0.116757  0.050246  0.052408 -0.012921   \n",
            "PC6      0.771894  0.481909 -0.001659  0.005881 -0.266795  0.038047  0.064784   \n",
            "PC7      0.611007 -0.602803  0.092239 -0.128936  0.303613  0.046552 -0.046378   \n",
            "PC8      0.051130  0.237551  0.370130  0.275886  0.509089 -0.364161 -0.325835   \n",
            "PC9     -0.059442 -0.053558  0.726878 -0.265338 -0.281959  0.262261  0.241201   \n",
            "PC10     0.029618 -0.221192 -0.108518  0.535560 -0.501518  0.071905 -0.065935   \n",
            "PC11     0.006054 -0.209752  0.349659  0.490011 -0.223084 -0.078374 -0.297773   \n",
            "PC12     0.041160 -0.069737 -0.292877  0.015586 -0.057025  0.014158 -0.005793   \n",
            "\n",
            "      Wellness       RPE  Duration  ...  Distance 14,4-19,8 km/h / min  \\\n",
            "PC1  -0.127471  0.264591  0.194859  ...                       0.259666   \n",
            "PC2   0.064182 -0.023826 -0.027642  ...                      -0.007632   \n",
            "PC3   0.404418 -0.100212 -0.189530  ...                       0.208010   \n",
            "PC4   0.318393  0.203554  0.320947  ...                      -0.161174   \n",
            "PC5  -0.015860 -0.105499 -0.251940  ...                       0.117339   \n",
            "PC6  -0.042417 -0.077697 -0.038256  ...                       0.014288   \n",
            "PC7   0.040349  0.093761  0.073067  ...                       0.016703   \n",
            "PC8   0.030953  0.073482 -0.056115  ...                      -0.058492   \n",
            "PC9  -0.020332 -0.032171  0.008295  ...                      -0.112110   \n",
            "PC10  0.054359  0.048239  0.015277  ...                       0.039764   \n",
            "PC11 -0.002141 -0.007092 -0.017749  ...                      -0.011537   \n",
            "PC12 -0.008034  0.075331 -0.155108  ...                      -0.352487   \n",
            "\n",
            "      Distance 19,8-25 km/h / min  Distance > 25 km/h / min  Dist Acc>3 / min  \\\n",
            "PC1                      0.216613                  0.225229          0.040464   \n",
            "PC2                     -0.000608                  0.015685          0.442145   \n",
            "PC3                      0.260725                  0.241611         -0.046689   \n",
            "PC4                     -0.197882                 -0.138777         -0.014098   \n",
            "PC5                      0.168330                  0.099196         -0.010256   \n",
            "PC6                      0.054865                 -0.020263          0.004324   \n",
            "PC7                     -0.083415                 -0.093812          0.008041   \n",
            "PC8                     -0.074760                  0.002758         -0.004820   \n",
            "PC9                      0.043545                  0.179721          0.005127   \n",
            "PC10                    -0.112455                 -0.246574         -0.002350   \n",
            "PC11                     0.102496                  0.154204         -0.000163   \n",
            "PC12                    -0.392057                  0.481095         -0.007698   \n",
            "\n",
            "      Dist Dec <-3 / min  Dist Acc 2-3 / min  Dist Dec 2-3 / min  \\\n",
            "PC1             0.039168            0.301618            0.296490   \n",
            "PC2             0.442362           -0.025480           -0.022000   \n",
            "PC3            -0.047109            0.025413            0.016554   \n",
            "PC4            -0.013864            0.041419            0.047445   \n",
            "PC5            -0.009447           -0.156612           -0.178847   \n",
            "PC6             0.004123           -0.045251           -0.045069   \n",
            "PC7             0.006801            0.111588            0.107599   \n",
            "PC8            -0.004695            0.106926            0.129734   \n",
            "PC9             0.003459            0.129940            0.165690   \n",
            "PC10           -0.002841            0.139158            0.126113   \n",
            "PC11           -0.000619           -0.073034           -0.050987   \n",
            "PC12           -0.005306            0.131730            0.215665   \n",
            "\n",
            "      Dist MP 20-35W / min  Dist MP 35-55W / min  Dist MP>55 W / min  \n",
            "PC1               0.280464              0.298520            0.280886  \n",
            "PC2              -0.012875             -0.013125           -0.011865  \n",
            "PC3               0.188708              0.173904            0.186734  \n",
            "PC4              -0.142465             -0.097782           -0.092243  \n",
            "PC5               0.103977              0.024330           -0.036509  \n",
            "PC6               0.009450             -0.003362           -0.000540  \n",
            "PC7               0.010133              0.024237           -0.036108  \n",
            "PC8              -0.055307              0.018821            0.083471  \n",
            "PC9              -0.057325              0.042376            0.180593  \n",
            "PC10              0.026194              0.030037           -0.093743  \n",
            "PC11             -0.000012              0.002059            0.065680  \n",
            "PC12             -0.320985             -0.088307            0.325958  \n",
            "\n",
            "[12 rows x 28 columns]\n",
            "Number of PCA Components: 12\n",
            "Feature Importance from Random Forest: [0.64433704 0.03986134 0.04772198 0.1647742  0.01551404 0.01043864\n",
            " 0.0081702  0.01252321 0.02423335 0.00860745 0.01120425 0.01261429]\n",
            "Best Model Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Mean Squared Error: 0.0046640925300985\n",
            "R-squared Score: 0.89841287770724\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ✅ Load dataset\n",
        "data = pd.read_excel('/content/your_file_converted copy.xlsx')\n",
        "\n",
        "# Drop irrelevant columns\n",
        "irrelevant_columns = ['Name', 'Date', 'Attendance', 'Profile', 'week', 'CMJ_Flag', 'CMJ_Flag_check', 'DayOfWeek']\n",
        "data = data.drop(columns=irrelevant_columns, errors='ignore')\n",
        "\n",
        "# ✅ Separate features (X) and target (y)\n",
        "X = data.drop(columns=['TL'], errors='ignore')\n",
        "y = data['TL']\n",
        "\n",
        "# ✅ Save original feature names before encoding\n",
        "original_features = X.columns.tolist()\n",
        "joblib.dump(original_features, 'original_features.pkl')\n",
        "print(f\"Original Features: {original_features}\")\n",
        "\n",
        "# ✅ Encode categorical variables\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
        "for col in categorical_columns:\n",
        "    X[col] = label_encoders[col].fit_transform(X[col])\n",
        "\n",
        "# ✅ Save label encoders\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "\n",
        "# ✅ Save feature order (to match during prediction)\n",
        "feature_order = X.columns.tolist()\n",
        "joblib.dump(feature_order, 'feature_order.pkl')\n",
        "print(f\"Feature Order after Encoding: {feature_order}\")\n",
        "\n",
        "# ✅ Standardize numerical features\n",
        "scaler_X = StandardScaler()\n",
        "X_standardized = scaler_X.fit_transform(X.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "# ✅ Save feature scaler\n",
        "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
        "\n",
        "# ✅ Scale the target variable (y) to [0, 1]\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# ✅ Save target scaler\n",
        "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
        "\n",
        "# ✅ Perform PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_standardized)\n",
        "\n",
        "# ✅ Save PCA model\n",
        "joblib.dump(pca, 'pca_model.pkl')\n",
        "\n",
        "# ✅ Choose number of components based on 95% variance\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "\n",
        "# Apply PCA with chosen components\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca_reduced = pca.fit_transform(X_standardized)\n",
        "joblib.dump(pca, 'updated_pca_model.pkl')\n",
        "\n",
        "# ✅ Name PCA components based on original features\n",
        "pca_feature_names = [f'PC{i+1}' for i in range(n_components)]\n",
        "pca_components_df = pd.DataFrame(pca.components_, columns=feature_order, index=pca_feature_names)\n",
        "print(\"PCA Component Contributions:\")\n",
        "print(pca_components_df)\n",
        "\n",
        "# ✅ Save PCA feature importance\n",
        "joblib.dump(pca_components_df, 'pca_feature_importance.pkl')\n",
        "print(f\"Number of PCA Components: {n_components}\")\n",
        "\n",
        "# ✅ Split data into train & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Hyperparameter tuning for RandomForest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Best model from hyperparameter tuning\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# ✅ Save trained model\n",
        "joblib.dump(best_rf_model, 'random_forest_model.pkl')\n",
        "\n",
        "# ✅ Make predictions & evaluate\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# ✅ Feature importance from Random Forest\n",
        "feature_importance_rf = best_rf_model.feature_importances_\n",
        "joblib.dump(feature_importance_rf, 'feature_importance_rf.pkl')\n",
        "print(f\"Feature Importance from Random Forest: {feature_importance_rf}\")\n",
        "\n",
        "print(f\"Best Model Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ✅ Load dataset\n",
        "data = pd.read_excel('/content/your_file_converted copy.xlsx')\n",
        "\n",
        "# Drop irrelevant columns\n",
        "irrelevant_columns = ['Name', 'Date', 'Attendance', 'Profile', 'week', 'CMJ_Flag', 'CMJ_Flag_check', 'DayOfWeek']\n",
        "data = data.drop(columns=irrelevant_columns, errors='ignore')\n",
        "\n",
        "# ✅ Separate features (X) and target (y)\n",
        "X = data.drop(columns=['TL'], errors='ignore')\n",
        "y = data['TL']\n",
        "\n",
        "# ✅ Save original feature names before encoding\n",
        "original_features = X.columns.tolist()\n",
        "joblib.dump(original_features, 'original_features.pkl')\n",
        "\n",
        "# ✅ Encode categorical variables\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
        "for col in categorical_columns:\n",
        "    X[col] = label_encoders[col].fit_transform(X[col])\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "\n",
        "# ✅ Save feature order\n",
        "feature_order = X.columns.tolist()\n",
        "joblib.dump(feature_order, 'feature_order.pkl')\n",
        "\n",
        "# ✅ Standardize numerical features\n",
        "scaler_X = StandardScaler()\n",
        "X_standardized = scaler_X.fit_transform(X.select_dtypes(include=['float64', 'int64']))\n",
        "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
        "\n",
        "# ✅ Scale the target variable (y) to [0, 1]\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
        "\n",
        "# ✅ Perform PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_standardized)\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca_reduced = pca.fit_transform(X_standardized)\n",
        "joblib.dump(pca, 'updated_pca_model.pkl')\n",
        "\n",
        "# ✅ Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Define models and hyperparameters\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"SVR\": SVR()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"RandomForest\": {'n_estimators': [50, 100], 'max_depth': [None, 10], 'min_samples_split': [2, 5]},\n",
        "    \"GradientBoosting\": {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]},\n",
        "    \"SVR\": {'C': [0.1, 1], 'kernel': ['rbf', 'linear']}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='r2', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        best_models[name] = best_model\n",
        "        joblib.dump(best_model, f'{name}_best_model.pkl')\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_models[name] = model\n",
        "        joblib.dump(model, f'{name}_model.pkl')\n",
        "\n",
        "    y_train_pred = best_models[name].predict(X_train)\n",
        "    y_test_pred = best_models[name].predict(X_test)\n",
        "\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Train MSE\": train_mse,\n",
        "        \"Test MSE\": test_mse,\n",
        "        \"Train R2\": train_r2,\n",
        "        \"Test R2\": test_r2\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "    print(f\"{name} - Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\\n\")\n",
        "\n",
        "print(\"Final Results:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvlD5q4BRs0A",
        "outputId": "f7a081b1-62a2-422c-9fac-06284147ca70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "RandomForest - Train MSE: 0.0007, Test MSE: 0.0047\n",
            "RandomForest - Train R2: 0.9844, Test R2: 0.8987\n",
            "\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'n_estimators': 100}\n",
            "GradientBoosting - Train MSE: 0.0016, Test MSE: 0.0049\n",
            "GradientBoosting - Train R2: 0.9659, Test R2: 0.8936\n",
            "\n",
            "LinearRegression - Train MSE: 0.0093, Test MSE: 0.0073\n",
            "LinearRegression - Train R2: 0.7978, Test R2: 0.8407\n",
            "\n",
            "Best parameters for SVR: {'C': 1, 'kernel': 'rbf'}\n",
            "SVR - Train MSE: 0.0036, Test MSE: 0.0042\n",
            "SVR - Train R2: 0.9213, Test R2: 0.9094\n",
            "\n",
            "Final Results: {'RandomForest': {'Train MSE': 0.0007162550760688895, 'Test MSE': 0.004650853086504874, 'Train R2': 0.9844437050942448, 'Test R2': 0.8987012418352572}, 'GradientBoosting': {'Train MSE': 0.0015716736318877027, 'Test MSE': 0.004883659597152485, 'Train R2': 0.9658649281099226, 'Test R2': 0.8936305569560252}, 'LinearRegression': {'Train MSE': 0.009307695797699637, 'Test MSE': 0.007315215532918156, 'Train R2': 0.7978467929096433, 'Test R2': 0.8406696071862108}, 'SVR': {'Train MSE': 0.003624385209359567, 'Test MSE': 0.004161482381541556, 'Train R2': 0.9212822260495481, 'Test R2': 0.9093600701777029}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ✅ Load dataset\n",
        "data = pd.read_excel('/content/your_file_converted copy.xlsx')\n",
        "\n",
        "# Drop irrelevant columns\n",
        "irrelevant_columns = ['Name', 'Date', 'Attendance', 'Profile', 'week', 'CMJ_Flag', 'CMJ_Flag_check', 'DayOfWeek']\n",
        "data = data.drop(columns=irrelevant_columns, errors='ignore')\n",
        "\n",
        "# ✅ Separate features (X) and target (y)\n",
        "X = data.drop(columns=['TL'], errors='ignore')\n",
        "y = data['TL']\n",
        "\n",
        "# ✅ Save original feature names before encoding\n",
        "original_features = X.columns.tolist()\n",
        "joblib.dump(original_features, 'original_features.pkl')\n",
        "\n",
        "# ✅ Encode categorical variables\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
        "for col in categorical_columns:\n",
        "    X[col] = label_encoders[col].fit_transform(X[col])\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "\n",
        "# ✅ Save feature order\n",
        "feature_order = X.columns.tolist()\n",
        "joblib.dump(feature_order, 'feature_order.pkl')\n",
        "\n",
        "# ✅ Standardize numerical features\n",
        "scaler_X = StandardScaler()\n",
        "X_standardized = scaler_X.fit_transform(X.select_dtypes(include=['float64', 'int64']))\n",
        "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
        "\n",
        "# ✅ Scale the target variable (y) to [0, 1]\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
        "\n",
        "# ✅ Perform PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_standardized)\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca_reduced = pca.fit_transform(X_standardized)\n",
        "joblib.dump(pca, 'updated_pca_model.pkl')\n",
        "\n",
        "# ✅ Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca_reduced, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Define models and hyperparameters\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"SVR\": SVR()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"RandomForest\": {'n_estimators': [50, 100], 'max_depth': [None, 10], 'min_samples_split': [2, 5]},\n",
        "    \"GradientBoosting\": {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]},\n",
        "    \"SVR\": {'C': [0.1, 1], 'kernel': ['rbf', 'linear']}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='r2', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        best_models[name] = best_model\n",
        "        joblib.dump(best_model, f'{name}_best_model.pkl')\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_models[name] = model\n",
        "        joblib.dump(model, f'{name}_model.pkl')\n",
        "\n",
        "    y_train_pred = best_models[name].predict(X_train)\n",
        "    y_test_pred = best_models[name].predict(X_test)\n",
        "\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Train MSE\": train_mse,\n",
        "        \"Test MSE\": test_mse,\n",
        "        \"Train R2\": train_r2,\n",
        "        \"Test R2\": test_r2\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "    print(f\"{name} - Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\\n\")\n",
        "\n",
        "# ✅ Save the best SVR model explicitly\n",
        "joblib.dump(best_models[\"SVR\"], \"SVR_best_model.pkl\")\n",
        "\n",
        "print(\"Final Results:\", results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDAkzmfbvoL1",
        "outputId": "4b78ec74-d218-403f-daf9-8406ca06936e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "RandomForest - Train MSE: 0.0007, Test MSE: 0.0047\n",
            "RandomForest - Train R2: 0.9844, Test R2: 0.8987\n",
            "\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'n_estimators': 100}\n",
            "GradientBoosting - Train MSE: 0.0016, Test MSE: 0.0049\n",
            "GradientBoosting - Train R2: 0.9659, Test R2: 0.8936\n",
            "\n",
            "LinearRegression - Train MSE: 0.0093, Test MSE: 0.0073\n",
            "LinearRegression - Train R2: 0.7978, Test R2: 0.8407\n",
            "\n",
            "Best parameters for SVR: {'C': 1, 'kernel': 'rbf'}\n",
            "SVR - Train MSE: 0.0036, Test MSE: 0.0042\n",
            "SVR - Train R2: 0.9213, Test R2: 0.9094\n",
            "\n",
            "Final Results: {'RandomForest': {'Train MSE': 0.0007162550760688895, 'Test MSE': 0.004650853086504874, 'Train R2': 0.9844437050942448, 'Test R2': 0.8987012418352572}, 'GradientBoosting': {'Train MSE': 0.0015716736318877027, 'Test MSE': 0.004883659597152485, 'Train R2': 0.9658649281099226, 'Test R2': 0.8936305569560252}, 'LinearRegression': {'Train MSE': 0.009307695797699637, 'Test MSE': 0.007315215532918156, 'Train R2': 0.7978467929096433, 'Test R2': 0.8406696071862108}, 'SVR': {'Train MSE': 0.003624385209359567, 'Test MSE': 0.004161482381541556, 'Train R2': 0.9212822260495481, 'Test R2': 0.9093600701777029}}\n"
          ]
        }
      ]
    }
  ]
}